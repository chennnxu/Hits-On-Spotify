{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a426becd-0068-4153-bd57-a81248d7ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import webbrowser\n",
    "import csv\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d846d9d-700b-4783-b709-25304231832a",
   "metadata": {},
   "source": [
    "### Step 1: Download top 200 weekly charts from 2017-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905f99a-2eac-4cb6-9f21-5715e80a120d",
   "metadata": {},
   "source": [
    "Website https://spotifycharts.com/regional\n",
    "<br>\n",
    "Conmment: this site have shut down since June 3rd, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1955a8e4-244a-45c2-9300-9d9feb2e52a6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getCharts():\n",
    "    # START AND END DATE FOR FIRST WEEK (YEAR, MONTH, DAY)\n",
    "    week_start = datetime.date(2016, 12, 30)\n",
    "    week_end = datetime.date(2017, 1, 6)\n",
    "    # ENDING DATE (YEAR, MONTH, DAY)\n",
    "    end_date = datetime.date(2021, 12, 31)\n",
    "    # end_date = datetime.date(2022, 6, 3)\n",
    "    delta = datetime.timedelta(days=7)\n",
    "\n",
    "    s_week = week_start\n",
    "    e_week = week_end     \n",
    "    while e_week <= end_date:\n",
    "        print(str(s_week)+\"--\"+str(e_week)+\" ----> \"+'global')\n",
    "        try:                        \n",
    "            # URL OF THE FILE FROM WEBSITE\n",
    "            url = \"https://spotifycharts.com/regional/global/weekly/{}--{}/download\".format(str(s_week),str(e_week))\n",
    "            webbrowser.open(url,autoraise=False)\n",
    "            # SLEEP FOR 2 SECONDS, JUST TO AVOID GETTING BLOCKED\n",
    "            time.sleep(2)            \n",
    "        except:\n",
    "            print(\"An Error Occur\")\n",
    "            pass\n",
    "        s_week += delta\n",
    "        e_week += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3eb4e20-e01f-42b2-acb3-b90b091158d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CALL THE FUNCTION\n",
    "# getCharts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac6b0ef-014d-4cd1-9147-041824904b6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Merge and preprocess all charts into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253f6f69-8d9e-484e-a877-f01d06fd71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "# GET ALL FILE NAMES\n",
    "all_filenames = os.path.join(\"/Users/xuchen/Documents/3MasterProject/spotify_charts\", \"*.csv\")\n",
    "all_filenames = glob.glob(all_filenames)\n",
    "print(len(all_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de6e7c8-b2db-4feb-b738-7ff01f65edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD HEADERS TO THE FILE IF IT DOES NOT ALREADY EXIST\n",
    "filepath = '/Users/xuchen/Documents/3MasterProject/'\n",
    "exist = path.exists(\"{}/top_200_weekly.csv\".format(filepath))\n",
    "if exist == False:\n",
    "    with open(\"{}top_200_weekly.csv\".format(filepath),\"w\",newline = '') as outFile:\n",
    "        writer = csv.writer(outFile)\n",
    "        writer.writerow(['Position','Track Name','Artist','Streams','URL','Week Start','Week End','ID','URI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09d880d-25c3-4e2f-988c-bd2e317fe1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "def preprocess(filename):\n",
    "    df = pd.read_csv(filename, skiprows=1)\n",
    "    s_week = filename[-26:-16]\n",
    "    e_week = filename[-14:-4]\n",
    "    df['Week_Start'] = str(s_week)\n",
    "    df['Week_End'] = str(e_week)\n",
    "    df['ID'] = df['URL'].str.replace('https://open.spotify.com/track/','')\n",
    "    df['URI'] = df['URL'].str.replace('https://open.spotify.com/track/','spotify:track:')\n",
    "    \n",
    "    df.to_csv('{}/top_200_weekly.csv'.format(filepath), \n",
    "              mode='a', header=False, index=False)\n",
    "    print(str(s_week)+\"--\"+str(e_week)+\" ----> \"+'global')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be7942e-a54d-4018-94be-9aee1887a0f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOW APPEND All FILE TO THE FINAL FILE\n",
    "# for f in all_filenames:\n",
    "#     preprocess(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5fefd-566e-4c43-baff-1017c7820bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
